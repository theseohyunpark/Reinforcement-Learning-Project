{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkYRro1YHAeG",
        "outputId": "10927caf-2a8f-4259-e530-a5e5d83940a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stable-baselines3\n",
            "  Downloading stable_baselines3-2.3.2-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sb3-contrib\n",
            "  Downloading sb3_contrib-2.3.0-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gymnasium<0.30,>=0.28.1 (from stable-baselines3)\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (2.3.0+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (2.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (3.7.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3) (4.11.0)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium<0.30,>=0.28.1->stable-baselines3)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (3.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13->stable-baselines3)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->stable-baselines3) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable-baselines3) (1.3.0)\n",
            "Installing collected packages: farama-notifications, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, gymnasium, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable-baselines3, sb3-contrib\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 sb3-contrib-2.3.0 stable-baselines3-2.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install stable-baselines3 sb3-contrib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU version\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "from sb3_contrib import TQC\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "import torch\n",
        "\n",
        "# Define custom environment class\n",
        "class InjectionMoldingEnv(gym.Env):\n",
        "    \"\"\"\n",
        "    Custom environment for injection molding process control.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Define observation space\n",
        "        self.observation_space = gym.spaces.Box(low=0, high=255, shape=(5,), dtype=np.float32)\n",
        "\n",
        "        # Define action space\n",
        "        self.action_space = gym.spaces.Box(low=-1.0, high=1.0, shape=(3,), dtype=np.float32)\n",
        "\n",
        "        # Initialize state variables\n",
        "        self.state = np.zeros(5, dtype=np.float32)\n",
        "        self.time = 0\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        # Reset state and timer for a new episode\n",
        "        super().reset(seed=seed)\n",
        "        self.state = np.random.rand(5).astype(np.float32)  # Example: Random initial state\n",
        "        self.time = 0\n",
        "        return self.state, {}  # Return the initial observation and an empty info dictionary\n",
        "\n",
        "    def step(self, action):\n",
        "        # Implement action logic and calculate reward\n",
        "        reward = 0  # Initialize reward\n",
        "\n",
        "        # Apply action (replace with action effects on state and reward)\n",
        "        # ... (modify based on your environment dynamics and action effects)\n",
        "\n",
        "        # Update state based on action and time\n",
        "        # (replace with appropriate state dynamics)\n",
        "        action = np.array(action, dtype=self.action_space.dtype)  # Convert action to the appropriate type\n",
        "        self.state[2:] += action  # Example: Action directly affects state\n",
        "\n",
        "        # Calculate reward based on process quality, cycle time, and other relevant factors\n",
        "        reward = -np.sum(np.abs(self.state[2:] - 1))  # Example: Reward for maintaining optimal state values\n",
        "\n",
        "        # Check for terminal state (replace with termination criteria)\n",
        "        terminated = False\n",
        "        truncated = False\n",
        "        if self.time > 200:  # Example: Maximum cycle time reached\n",
        "            terminated = True\n",
        "\n",
        "        self.time += 1\n",
        "        return self.state, reward, terminated, truncated, {}  # Return the state, reward, terminated flag, truncated flag, and an empty info dictionary\n",
        "\n",
        "# Create a callback to track training progress\n",
        "class TrainingCallback(BaseCallback):\n",
        "    def __init__(self, check_freq: int, save_path: str, verbose=1):\n",
        "        super(TrainingCallback, self).__init__(verbose)\n",
        "        self.check_freq = check_freq\n",
        "        self.save_path = save_path\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        if self.n_calls % self.check_freq == 0:\n",
        "            # Save the model every check_freq steps\n",
        "            self.model.save(self.save_path)\n",
        "        return True\n",
        "\n",
        "# Create the custom environment\n",
        "env = InjectionMoldingEnv()\n",
        "\n",
        "# Define learning rate schedule (optional, can be a constant value)\n",
        "def linear_lr_schedule(current_progress_remaining):\n",
        "    return 0.001 * current_progress_remaining  # Adjust learning rate decay as needed\n",
        "\n",
        "# Create TQC model\n",
        "model = TQC(\"MlpPolicy\", env, learning_rate=linear_lr_schedule, verbose=1, device=\"cuda\")\n",
        "\n",
        "# Define the total number of training timesteps\n",
        "total_timesteps = 100000  # Adjust based on experiment requirements\n",
        "\n",
        "# Define the callback for saving the model during training\n",
        "callback = TrainingCallback(check_freq=1000, save_path=\"./tqc_injection_molding_model\")\n",
        "\n",
        "# Train the model\n",
        "model.learn(total_timesteps=total_timesteps, callback=callback)\n",
        "\n",
        "# Evaluate the trained model\n",
        "num_episodes = 10\n",
        "rewards = []\n",
        "\n",
        "for _ in range(num_episodes):\n",
        "    observation = env.reset()[0]  # Reset returns a tuple (observation, info)\n",
        "    episode_reward = 0\n",
        "    done = False\n",
        "    while not done:\n",
        "        action, _states = model.predict(observation, deterministic=True)\n",
        "        ction = np.array(action, dtype=env.action_space.dtype)  # Convert action to the appropriate type\n",
        "        observation, reward, done, truncated, info = env.step(action)\n",
        "        episode_reward += reward\n",
        "        if done or truncated:\n",
        "            break\n",
        "    rewards.append(episode_reward)\n",
        "\n",
        "print(f\"Average reward over {num_episodes} episodes: {np.mean(rewards)}\")\n",
        "\n",
        "# Close the environment\n",
        "env.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6v6gwt0IckA",
        "outputId": "1556a208-a174-46c0-eb6c-14a54cc5f1a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 202      |\n",
            "|    ep_rew_mean     | -803     |\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 78       |\n",
            "|    time_elapsed    | 10       |\n",
            "|    total_timesteps | 808      |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 8.96     |\n",
            "|    critic_loss     | 0.145    |\n",
            "|    ent_coef        | 0.698    |\n",
            "|    ent_coef_loss   | -1.21    |\n",
            "|    learning_rate   | 0.000193 |\n",
            "|    n_updates       | 707      |\n",
            "---------------------------------\n",
            "Average reward over 100 episodes: -69.74166525602341\n"
          ]
        }
      ]
    }
  ]
}