{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install 'gymnasium<0.30,>=0.28.1'\n",
        "!pip install sb3-contrib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UPOuTAmAsKK",
        "outputId": "8f3c6988-1d59-41b4-fac4-acb61c80fd06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.10/dist-packages (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1) (4.11.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1) (0.0.4)\n",
            "Collecting sb3-contrib\n",
            "  Downloading sb3_contrib-2.3.0-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: stable-baselines3<3.0,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from sb3-contrib) (2.3.2)\n",
            "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3<3.0,>=2.3.0->sb3-contrib) (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3<3.0,>=2.3.0->sb3-contrib) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3<3.0,>=2.3.0->sb3-contrib) (2.3.0+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3<3.0,>=2.3.0->sb3-contrib) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3<3.0,>=2.3.0->sb3-contrib) (2.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3<3.0,>=2.3.0->sb3-contrib) (3.7.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3<3.0,>=2.3.0->sb3-contrib) (4.11.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3<3.0,>=2.3.0->sb3-contrib) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib) (3.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib) (12.5.40)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<3.0,>=2.3.0->sb3-contrib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<3.0,>=2.3.0->sb3-contrib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<3.0,>=2.3.0->sb3-contrib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<3.0,>=2.3.0->sb3-contrib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<3.0,>=2.3.0->sb3-contrib) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<3.0,>=2.3.0->sb3-contrib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<3.0,>=2.3.0->sb3-contrib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<3.0,>=2.3.0->sb3-contrib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3<3.0,>=2.3.0->sb3-contrib) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3<3.0,>=2.3.0->sb3-contrib) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3<3.0,>=2.3.0->sb3-contrib) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib) (1.3.0)\n",
            "Installing collected packages: sb3-contrib\n",
            "Successfully installed sb3-contrib-2.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fupGGmoXAme0",
        "outputId": "abbd1b61-093f-4f20-a9dc-1ab6155dfc51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 202      |\n",
            "|    ep_rew_mean     | -881     |\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 22       |\n",
            "|    time_elapsed    | 36       |\n",
            "|    total_timesteps | 808      |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 8.87     |\n",
            "|    critic_loss     | 0.0503   |\n",
            "|    ent_coef        | 0.548    |\n",
            "|    ent_coef_loss   | -1.91    |\n",
            "|    learning_rate   | 0.000919 |\n",
            "|    n_updates       | 707      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 202      |\n",
            "|    ep_rew_mean     | -531     |\n",
            "| time/              |          |\n",
            "|    episodes        | 8        |\n",
            "|    fps             | 19       |\n",
            "|    time_elapsed    | 83       |\n",
            "|    total_timesteps | 1616     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 8.44     |\n",
            "|    critic_loss     | 0.0219   |\n",
            "|    ent_coef        | 0.299    |\n",
            "|    ent_coef_loss   | -3.06    |\n",
            "|    learning_rate   | 0.000839 |\n",
            "|    n_updates       | 1515     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 202      |\n",
            "|    ep_rew_mean     | -400     |\n",
            "| time/              |          |\n",
            "|    episodes        | 12       |\n",
            "|    fps             | 19       |\n",
            "|    time_elapsed    | 126      |\n",
            "|    total_timesteps | 2424     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 10.7     |\n",
            "|    critic_loss     | 0.031    |\n",
            "|    ent_coef        | 0.175    |\n",
            "|    ent_coef_loss   | -3.85    |\n",
            "|    learning_rate   | 0.000758 |\n",
            "|    n_updates       | 2323     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 202      |\n",
            "|    ep_rew_mean     | -324     |\n",
            "| time/              |          |\n",
            "|    episodes        | 16       |\n",
            "|    fps             | 18       |\n",
            "|    time_elapsed    | 170      |\n",
            "|    total_timesteps | 3232     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 10.4     |\n",
            "|    critic_loss     | 0.00966  |\n",
            "|    ent_coef        | 0.116    |\n",
            "|    ent_coef_loss   | -3.19    |\n",
            "|    learning_rate   | 0.000677 |\n",
            "|    n_updates       | 3131     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 202      |\n",
            "|    ep_rew_mean     | -274     |\n",
            "| time/              |          |\n",
            "|    episodes        | 20       |\n",
            "|    fps             | 18       |\n",
            "|    time_elapsed    | 213      |\n",
            "|    total_timesteps | 4040     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 10.4     |\n",
            "|    critic_loss     | 0.00541  |\n",
            "|    ent_coef        | 0.0869   |\n",
            "|    ent_coef_loss   | -2.61    |\n",
            "|    learning_rate   | 0.000596 |\n",
            "|    n_updates       | 3939     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 202      |\n",
            "|    ep_rew_mean     | -238     |\n",
            "| time/              |          |\n",
            "|    episodes        | 24       |\n",
            "|    fps             | 19       |\n",
            "|    time_elapsed    | 255      |\n",
            "|    total_timesteps | 4848     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 14.9     |\n",
            "|    critic_loss     | 0.0323   |\n",
            "|    ent_coef        | 0.0727   |\n",
            "|    ent_coef_loss   | -0.178   |\n",
            "|    learning_rate   | 0.000515 |\n",
            "|    n_updates       | 4747     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 202      |\n",
            "|    ep_rew_mean     | -211     |\n",
            "| time/              |          |\n",
            "|    episodes        | 28       |\n",
            "|    fps             | 18       |\n",
            "|    time_elapsed    | 297      |\n",
            "|    total_timesteps | 5656     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.7     |\n",
            "|    critic_loss     | 0.0665   |\n",
            "|    ent_coef        | 0.0666   |\n",
            "|    ent_coef_loss   | -0.317   |\n",
            "|    learning_rate   | 0.000434 |\n",
            "|    n_updates       | 5555     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 202      |\n",
            "|    ep_rew_mean     | -191     |\n",
            "| time/              |          |\n",
            "|    episodes        | 32       |\n",
            "|    fps             | 18       |\n",
            "|    time_elapsed    | 340      |\n",
            "|    total_timesteps | 6464     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 14.4     |\n",
            "|    critic_loss     | 0.0299   |\n",
            "|    ent_coef        | 0.0649   |\n",
            "|    ent_coef_loss   | -0.153   |\n",
            "|    learning_rate   | 0.000354 |\n",
            "|    n_updates       | 6363     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 202      |\n",
            "|    ep_rew_mean     | -175     |\n",
            "| time/              |          |\n",
            "|    episodes        | 36       |\n",
            "|    fps             | 19       |\n",
            "|    time_elapsed    | 381      |\n",
            "|    total_timesteps | 7272     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 14.6     |\n",
            "|    critic_loss     | 0.0533   |\n",
            "|    ent_coef        | 0.0652   |\n",
            "|    ent_coef_loss   | -0.526   |\n",
            "|    learning_rate   | 0.000273 |\n",
            "|    n_updates       | 7171     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 202      |\n",
            "|    ep_rew_mean     | -162     |\n",
            "| time/              |          |\n",
            "|    episodes        | 40       |\n",
            "|    fps             | 19       |\n",
            "|    time_elapsed    | 424      |\n",
            "|    total_timesteps | 8080     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 17.1     |\n",
            "|    critic_loss     | 0.0341   |\n",
            "|    ent_coef        | 0.0659   |\n",
            "|    ent_coef_loss   | 0.107    |\n",
            "|    learning_rate   | 0.000192 |\n",
            "|    n_updates       | 7979     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 202      |\n",
            "|    ep_rew_mean     | -151     |\n",
            "| time/              |          |\n",
            "|    episodes        | 44       |\n",
            "|    fps             | 19       |\n",
            "|    time_elapsed    | 466      |\n",
            "|    total_timesteps | 8888     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 18.1     |\n",
            "|    critic_loss     | 0.00457  |\n",
            "|    ent_coef        | 0.0665   |\n",
            "|    ent_coef_loss   | 0.137    |\n",
            "|    learning_rate   | 0.000111 |\n",
            "|    n_updates       | 8787     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 202      |\n",
            "|    ep_rew_mean     | -142     |\n",
            "| time/              |          |\n",
            "|    episodes        | 48       |\n",
            "|    fps             | 19       |\n",
            "|    time_elapsed    | 507      |\n",
            "|    total_timesteps | 9696     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 19.2     |\n",
            "|    critic_loss     | 0.035    |\n",
            "|    ent_coef        | 0.0666   |\n",
            "|    ent_coef_loss   | 0.0732   |\n",
            "|    learning_rate   | 3.05e-05 |\n",
            "|    n_updates       | 9595     |\n",
            "---------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "too many values to unpack (expected 4)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-8cde3e580bd7>\u001b[0m in \u001b[0;36m<cell line: 96>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0mepisode_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode_reward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
          ]
        }
      ],
      "source": [
        "# CPU Version\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "from sb3_contrib import TQC\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "import torch\n",
        "\n",
        "# Define custom environment class\n",
        "class InjectionMoldingEnv(gym.Env):\n",
        "    \"\"\"\n",
        "    Custom environment for injection molding process control.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Define observation space\n",
        "        self.observation_space = gym.spaces.Box(low=0, high=255, shape=(5,), dtype=np.float32)\n",
        "\n",
        "        # Define action space\n",
        "        self.action_space = gym.spaces.Box(low=-1.0, high=1.0, shape=(3,), dtype=np.float32)\n",
        "\n",
        "        # Initialize state variables\n",
        "        self.state = np.zeros(5, dtype=np.float32)\n",
        "        self.time = 0\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        # Reset state and timer for a new episode\n",
        "        super().reset(seed=seed)\n",
        "        self.state = np.random.rand(5).astype(np.float32)  # Example: Random initial state\n",
        "        self.time = 0\n",
        "        return self.state, {}  # Return the initial observation and an empty info dictionary\n",
        "\n",
        "    def step(self, action):\n",
        "        # Implement action logic and calculate reward\n",
        "        reward = 0  # Initialize reward\n",
        "\n",
        "        # Apply action (replace with action effects on state and reward)\n",
        "        # ... (modify based on your environment dynamics and action effects)\n",
        "\n",
        "        # Update state based on action and time\n",
        "        # (replace with appropriate state dynamics)\n",
        "        self.state[2:] += action  # Example: Action directly affects state\n",
        "\n",
        "        # Calculate reward based on process quality, cycle time, and other relevant factors\n",
        "        reward = -np.sum(np.abs(self.state[2:] - 1))  # Example: Reward for maintaining optimal state values\n",
        "\n",
        "        # Check for terminal state (replace with termination criteria)\n",
        "        terminated = False\n",
        "        truncated = False\n",
        "        if self.time > 200:  # Example: Maximum cycle time reached\n",
        "            terminated = True\n",
        "\n",
        "        self.time += 1\n",
        "        return self.state, reward, terminated, truncated, {}  # Return the state, reward, terminated flag, truncated flag, and an empty info dictionary\n",
        "\n",
        "\n",
        "\n",
        "# Create a callback to track training progress\n",
        "class TrainingCallback(BaseCallback):\n",
        "    def __init__(self, check_freq: int, save_path: str, verbose=1):\n",
        "        super(TrainingCallback, self).__init__(verbose)\n",
        "        self.check_freq = check_freq\n",
        "        self.save_path = save_path\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        if self.n_calls % self.check_freq == 0:\n",
        "            # Save the model every check_freq steps\n",
        "            self.model.save(self.save_path)\n",
        "        return True\n",
        "\n",
        "# Create the custom environment\n",
        "env = InjectionMoldingEnv()\n",
        "\n",
        "# Define learning rate schedule (optional, can be a constant value)\n",
        "def linear_lr_schedule(current_progress_remaining):\n",
        "    return 0.001 * current_progress_remaining  # Adjust learning rate decay as needed\n",
        "\n",
        "# Create TQC model\n",
        "model = TQC(\"MlpPolicy\", env, learning_rate=linear_lr_schedule, verbose=1)\n",
        "\n",
        "# Define the total number of training timesteps\n",
        "total_timesteps = 100000  # Adjust based on experiment requirements\n",
        "\n",
        "# Define the callback for saving the model during training\n",
        "callback = TrainingCallback(check_freq=1000, save_path=\"./tqc_injection_molding_model\")\n",
        "\n",
        "# Train the model\n",
        "model.learn(total_timesteps=total_timesteps, callback=callback)\n",
        "\n",
        "# Evaluate the trained model\n",
        "num_episodes = 10\n",
        "rewards = []\n",
        "\n",
        "for _ in range(num_episodes):\n",
        "    observation = env.reset()[0]  # Reset returns a tuple (observation, info)\n",
        "    episode_reward = 0\n",
        "    done = False\n",
        "    while not done:\n",
        "        action, _states = model.predict(observation, deterministic=True)\n",
        "        observation, reward, done, info = env.step(action)\n",
        "        episode_reward += reward\n",
        "    rewards.append(episode_reward)\n",
        "\n",
        "print(f\"Average reward over {num_episodes} episodes: {np.mean(rewards)}\")\n",
        "\n",
        "# Close the environment\n",
        "env.close()"
      ]
    }
  ]
}